---
sidebar_position: 1
title: v10 to v13 Migration
description: 마이그레이션 계획
---

# Migration Plan: v10 → v13

> 기존 데이터 보존하면서 새 스키마로 이전

---

## 목표

1. **데이터 손실 없음** - 기존 데이터 100% 보존
2. **최소 다운타임** - 서비스 중단 최소화
3. **롤백 가능** - 문제 시 즉시 복구

---

## 현재 v10 스키마 구조

### 주요 테이블 (추정)

```
v10 스키마
├── public (또는 기본)
│   ├── stocks              # 종목 마스터
│   ├── prices              # 일별 가격
│   ├── fundamentals        # 재무 데이터
│   └── investor            # 투자자별 매매동향 (수급)
│
├── brain
│   ├── analysis_results    # Brain 분석 결과
│   ├── stage_outputs       # 스테이지별 출력
│   └── ai_analysis_log     # AI 분석 로그
│
├── execution
│   ├── orders              # 주문
│   ├── executions          # 체결
│   └── positions           # 포지션
│
├── feedback
│   ├── learning_data       # 학습 데이터
│   └── performance         # 성과
│
├── forecast
│   ├── predictions         # 예측
│   └── events              # 이벤트
│
└── portfolio
    ├── holdings            # 보유
    └── balance_snapshots   # 잔고 스냅샷
```

---

## v13 신규 스키마 구조

```
v13 스키마
├── data                    # S0-S1: 원천 데이터
│   ├── stocks
│   ├── prices
│   ├── fundamentals
│   ├── investor_flow       # 투자자별 매매동향 (수급) ⭐
│   ├── quality_snapshots
│   └── universe_snapshots
│
├── signals                 # S2: 시그널
│   ├── factor_scores       # flow 컬럼 포함 ⭐
│   ├── flow_details        # 수급 상세 시그널 ⭐
│   ├── events
│   └── signal_snapshots
│
├── selection               # S3-S4: 스크리닝/랭킹
│   ├── screened
│   └── ranked
│
├── portfolio               # S5: 포트폴리오
│   ├── targets
│   └── holdings
│
├── execution               # S6: 주문
│   ├── orders
│   └── executions
│
└── audit                   # S7: 성과
    ├── daily_snapshots
    ├── performance_reports
    └── attributions
```

---

## 테이블 매핑

### 1:1 매핑 (구조 유지)

| v10 | v13 | 변경사항 |
|-----|-----|----------|
| `stocks` | `data.stocks` | 스키마만 이동 |
| `prices` | `data.prices` | 스키마만 이동 |
| `fundamentals` | `data.fundamentals` | 스키마만 이동 |
| `investor` | `data.investor_flow` | 스키마 이동 + 컬럼 표준화 ⭐ |
| `execution.orders` | `execution.orders` | 유지 |
| `execution.executions` | `execution.executions` | 유지 |
| `portfolio.holdings` | `portfolio.holdings` | 유지 |

### 변환 필요

| v10 | v13 | 변환 방법 |
|-----|-----|----------|
| `brain.analysis_results` | `signals.factor_scores` | JSON 파싱 후 컬럼 분리 (flow 컬럼 추가) |
| `data.investor_flow` | `signals.flow_details` | 5D/20D 누적 계산 ⭐ |
| `brain.stage_outputs` | `selection.ranked` | 필요 필드만 추출 |
| `forecast.events` | `signals.events` | 구조 재매핑 |
| `feedback.performance` | `audit.performance_reports` | 집계 재계산 |
| `portfolio.balance_snapshots` | `audit.daily_snapshots` | 구조 확장 |

### 삭제 (마이그레이션 안함)

| v10 테이블 | 이유 |
|------------|------|
| `brain.ai_analysis_log` | 로그성 데이터, 새로 축적 |
| `brain.stage_outputs` (일부) | 중간 결과, 재계산 가능 |
| `feedback.learning_data` | 새 구조로 재학습 |

---

## 마이그레이션 전략

### Option A: View 기반 (권장)

**장점**: 무중단, 점진적, 안전
**단점**: 복잡도 증가, View 성능

```sql
-- 1단계: 새 스키마 생성
CREATE SCHEMA data;
CREATE SCHEMA signals;
-- ...

-- 2단계: View로 기존 데이터 노출
CREATE VIEW data.stocks AS
SELECT * FROM public.stocks;

CREATE VIEW data.prices AS
SELECT * FROM public.prices;

-- 3단계: 코드에서 새 경로 사용
-- internal/data/repository.go
-- FROM: SELECT * FROM stocks
-- TO:   SELECT * FROM data.stocks

-- 4단계: View → 실제 테이블로 전환 (나중에)
```

### Option B: Rename 기반

**장점**: 빠름, 단순
**단점**: 한번에 전환 필요, 롤백 어려움

```sql
-- 1단계: 새 스키마 생성
CREATE SCHEMA data;

-- 2단계: 테이블 이동
ALTER TABLE public.stocks SET SCHEMA data;
ALTER TABLE public.prices SET SCHEMA data;

-- 3단계: 코드 일괄 변경
```

### Option C: 하이브리드 (권장)

**핵심 테이블**: Rename (빠른 전환)
**복잡한 테이블**: View (점진적 전환)

```sql
-- 핵심 테이블: 즉시 이동
ALTER TABLE public.stocks SET SCHEMA data;
ALTER TABLE public.prices SET SCHEMA data;

-- 복잡한 테이블: View 먼저
CREATE VIEW signals.factor_scores AS
SELECT
    date,
    code,
    (result->>'momentum')::decimal as momentum,
    (result->>'value')::decimal as value
FROM brain.analysis_results;
```

---

## 실행 계획

### Phase 1: 준비 (1일)

```sql
-- 1. 백업
pg_dump -h localhost -U aegis aegis_v10 > backup_v10_$(date +%Y%m%d).sql

-- 2. 새 스키마 생성
CREATE SCHEMA IF NOT EXISTS data;
CREATE SCHEMA IF NOT EXISTS signals;
CREATE SCHEMA IF NOT EXISTS selection;
CREATE SCHEMA IF NOT EXISTS portfolio;
CREATE SCHEMA IF NOT EXISTS execution;
CREATE SCHEMA IF NOT EXISTS audit;

-- 3. 현재 데이터 크기 확인
SELECT
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
    n_live_tup as rows
FROM pg_stat_user_tables
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

### Phase 2: 핵심 테이블 이동 (1일)

```sql
-- 종목/가격 데이터 이동 (대용량, 빠른 이동 필요)
ALTER TABLE public.stocks SET SCHEMA data;
ALTER TABLE public.prices SET SCHEMA data;
ALTER TABLE public.fundamentals SET SCHEMA data;

-- 투자자 수급 데이터 이동 ⭐
ALTER TABLE public.investor RENAME TO investor_flow;
ALTER TABLE public.investor_flow SET SCHEMA data;

-- 주문/체결 데이터 이동
ALTER TABLE execution.orders SET SCHEMA execution;
-- (이미 execution 스키마면 유지)

-- 포트폴리오 데이터 이동
ALTER TABLE portfolio.holdings SET SCHEMA portfolio;
```

### Phase 3: 변환 테이블 (2-3일)

```sql
-- signals.factor_scores 생성 및 데이터 변환 (flow 컬럼 포함 ⭐)
CREATE TABLE signals.factor_scores (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL,
    code VARCHAR(10) NOT NULL,
    momentum DECIMAL(8,4),
    value DECIMAL(8,4),
    quality DECIMAL(8,4),
    flow DECIMAL(8,4),        -- 수급 시그널 ⭐
    event DECIMAL(8,4),
    created_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(date, code)
);

-- v10 brain 결과에서 추출 (flow는 별도 계산 필요)
INSERT INTO signals.factor_scores (date, code, momentum, value, quality, flow, event)
SELECT
    date,
    code,
    (scores->>'momentum')::decimal,
    (scores->>'value')::decimal,
    (scores->>'quality')::decimal,
    0.0,  -- flow는 flow_details에서 별도 계산 후 업데이트
    (scores->>'event')::decimal
FROM brain.analysis_results
WHERE date >= '2024-01-01';  -- 최근 데이터만

-- signals.flow_details 생성 (수급 상세 시그널) ⭐
CREATE TABLE signals.flow_details (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL,
    stock_code VARCHAR(10) NOT NULL,
    foreign_net_5d BIGINT,      -- 외국인 5일 순매수
    foreign_net_20d BIGINT,     -- 외국인 20일 순매수
    inst_net_5d BIGINT,         -- 기관 5일 순매수
    inst_net_20d BIGINT,        -- 기관 20일 순매수
    flow_score DECIMAL(8,4),    -- 종합 수급 점수
    created_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(date, stock_code)
);

-- investor_flow에서 5일/20일 누적 계산하여 flow_details 생성
INSERT INTO signals.flow_details (date, stock_code, foreign_net_5d, foreign_net_20d, inst_net_5d, inst_net_20d, flow_score)
SELECT
    f.date,
    f.stock_code,
    SUM(f2.foreign_net) FILTER (WHERE f2.date > f.date - INTERVAL '5 days') as foreign_net_5d,
    SUM(f2.foreign_net) FILTER (WHERE f2.date > f.date - INTERVAL '20 days') as foreign_net_20d,
    SUM(f2.inst_net) FILTER (WHERE f2.date > f.date - INTERVAL '5 days') as inst_net_5d,
    SUM(f2.inst_net) FILTER (WHERE f2.date > f.date - INTERVAL '20 days') as inst_net_20d,
    0.0  -- flow_score는 애플리케이션에서 계산
FROM data.investor_flow f
JOIN data.investor_flow f2 ON f.stock_code = f2.stock_code AND f2.date <= f.date
WHERE f.date >= '2024-01-01'
GROUP BY f.date, f.stock_code;

-- factor_scores의 flow 값 업데이트
UPDATE signals.factor_scores fs
SET flow = fd.flow_score
FROM signals.flow_details fd
WHERE fs.date = fd.date AND fs.code = fd.stock_code;

-- signals.events 생성
CREATE TABLE signals.events (
    id SERIAL PRIMARY KEY,
    code VARCHAR(10) NOT NULL,
    event_date DATE NOT NULL,
    event_type VARCHAR(50),
    score DECIMAL(5,2),
    source VARCHAR(30),
    raw_data JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

INSERT INTO signals.events (code, event_date, event_type, score, source, raw_data)
SELECT
    code,
    event_date,
    type,
    score,
    source,
    raw_data
FROM forecast.events;
```

### Phase 4: 검증 (1일)

```sql
-- 데이터 정합성 체크
SELECT 'stocks' as table_name,
       (SELECT COUNT(*) FROM data.stocks) as v13_count,
       (SELECT COUNT(*) FROM backup.stocks) as v10_count;

SELECT 'prices' as table_name,
       (SELECT COUNT(*) FROM data.prices) as v13_count,
       (SELECT COUNT(*) FROM backup.prices) as v10_count;

-- 투자자 수급 데이터 검증 ⭐
SELECT 'investor_flow' as table_name,
       (SELECT COUNT(*) FROM data.investor_flow) as v13_count,
       (SELECT COUNT(*) FROM backup.investor) as v10_count;

SELECT 'flow_details' as table_name,
       (SELECT COUNT(*) FROM signals.flow_details) as count;

-- 샘플 데이터 비교
SELECT * FROM data.prices WHERE code = '005930' ORDER BY date DESC LIMIT 5;
SELECT * FROM backup.prices WHERE code = '005930' ORDER BY date DESC LIMIT 5;

-- 수급 데이터 샘플 검증 ⭐
SELECT * FROM data.investor_flow WHERE stock_code = '005930' ORDER BY date DESC LIMIT 5;
SELECT * FROM signals.flow_details WHERE stock_code = '005930' ORDER BY date DESC LIMIT 5;
```

### Phase 5: 정리 (1일)

```sql
-- 기존 테이블 백업 스키마로 이동 (삭제 대신)
CREATE SCHEMA backup_v10;
ALTER TABLE brain.analysis_results SET SCHEMA backup_v10;
ALTER TABLE forecast.events SET SCHEMA backup_v10;

-- 1주일 후 문제없으면 삭제
-- DROP SCHEMA backup_v10 CASCADE;
```

---

## 롤백 계획

### 즉시 롤백 (Phase 2-3 중)

```sql
-- 트랜잭션 롤백
ROLLBACK;

-- 또는 백업에서 복원
psql -h localhost -U aegis aegis_v10 < backup_v10_YYYYMMDD.sql
```

### 부분 롤백 (Phase 4-5 후)

```sql
-- backup_v10 스키마에서 복원
ALTER TABLE backup_v10.analysis_results SET SCHEMA brain;

-- View 제거 후 원본 테이블 복원
DROP VIEW IF EXISTS signals.factor_scores;
```

---

## 코드 마이그레이션

### Repository 변경

```go
// v10
func (r *Repository) GetPrices(code string) ([]Price, error) {
    query := `SELECT * FROM prices WHERE code = $1`
    // ...
}

// v13
func (r *Repository) GetPrices(code string) ([]Price, error) {
    query := `SELECT * FROM data.prices WHERE code = $1`
    // ...
}
```

### 점진적 전환 (Feature Flag)

```go
func (r *Repository) GetPrices(code string) ([]Price, error) {
    var query string
    if r.config.UseNewSchema {
        query = `SELECT * FROM data.prices WHERE code = $1`
    } else {
        query = `SELECT * FROM prices WHERE code = $1`
    }
    // ...
}
```

---

## 타임라인

| 일차 | 작업 | 예상 시간 | 롤백 가능 |
|------|------|----------|----------|
| D-1 | 백업, 스키마 생성 | 2시간 | ✅ |
| D+0 | 핵심 테이블 이동 | 1시간 | ✅ |
| D+1 | 변환 테이블 생성 | 4시간 | ✅ |
| D+2 | 데이터 변환 | 4시간 | ✅ |
| D+3 | 검증 | 4시간 | ✅ |
| D+4 | 코드 배포 | 2시간 | ⚠️ |
| D+5 | 모니터링 | - | ⚠️ |
| D+12 | 기존 스키마 삭제 | 1시간 | ❌ |

---

## 체크리스트

### 마이그레이션 전
- [ ] 전체 백업 완료
- [ ] 백업 복원 테스트
- [ ] 새 스키마 생성
- [ ] 데이터 크기/row 수 기록

### 마이그레이션 중
- [ ] 핵심 테이블 이동
- [ ] investor → investor_flow 이름 변경 및 이동
- [ ] 변환 테이블 생성
- [ ] flow_details 테이블 생성 및 데이터 계산
- [ ] factor_scores flow 컬럼 업데이트
- [ ] 데이터 변환 완료
- [ ] 인덱스 생성

### 마이그레이션 후
- [ ] row 수 비교 검증
- [ ] 샘플 데이터 비교
- [ ] investor_flow 수급 데이터 검증
- [ ] flow_details 누적 계산 검증
- [ ] 애플리케이션 테스트
- [ ] 성능 테스트

---

**Next**: [API Specification](../api/specification.md)
